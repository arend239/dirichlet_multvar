---
title: "TAREFA 4 Análise de Tópicos com LDA em Resenhas de Filmes (IMDB) - Análise Multivariada"
author: "Márcia Barbian"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}
# install.packages(c("tidytext", "textdata", "dplyr", "ggplot2", "tm", "topicmodels", "textclean"))

library(tidytext)
library(textdata)
library(dplyr)
library(ggplot2)
library(tm)
library(topicmodels)
library(textclean)
library(readr)
library(stringr)
library(janeaustenr)
library(stm)
library(wordcloud)
library(MCMCpack)
library(tidyverse)

set.seed(42)
```

## Objetivo

Este exercício tem como objetivo identificar **tópicos latentes** em resenhas de filmes utilizando o modelo **LDA (Latent Dirichlet Allocation)** com dados reais da base IMDB. O banco de dados está disponível no link: <http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz> Descompacte esse arquivo e coloque a pasta aclImdb na mesma pasta do projeto da tarefa 4.

OBS: A base é muito grande, então você deve escolher um parte dela.

Antes de fazer o exerício veja os vídeos: <https://www.youtube.com/watch?v=T05t-SqKArY&t=1473s> e <https://www.youtube.com/watch?v=BaM1uiCpj_E>

Veja o livro: <https://www.tidytextmining.com/>

```{r}
# Carregar base IMDB reduzida (1000 exemplos)

path_pos <- "aclImdb/train/pos"
path_neg <- "aclImdb/train/neg"

# Listar os arquivos .txt
files_pos <- list.files(path_pos, full.names = TRUE)
files_neg <- list.files(path_neg, full.names = TRUE)

head(files_pos)

files_pos_amostra = files_pos[sample(1:length(files_pos), 500)]
files_neg_amostra  = files_neg[sample(1:length(files_neg), 500)]

# Ler os textos
pos_reviews <- sapply(files_pos_amostra, read_file)
neg_reviews <- sapply(files_neg_amostra, read_file)

# Montar data frame com rótulo
imdb <- data.frame(
  review = c(pos_reviews, neg_reviews),
  sentiment = c(rep("pos", length(pos_reviews)), rep("neg", length(neg_reviews))),
  stringsAsFactors = FALSE
)

# Visualizar
head(imdb)

```

```{r}

# Substituir contrações e símbolos
imdb$review <- replace_contraction(imdb$review)
imdb$review <- replace_symbol(imdb$review)

# Criar corpus e limpar
corpus <- Corpus(VectorSource(imdb$review))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stripWhitespace)

# Matriz documento-termo
dtm <- DocumentTermMatrix(corpus)
dtm <- removeSparseTerms(dtm, 0.99)
dtm
```

## Palavras mais frequentes

```{r}

# Transformar em tibble para tidytext
reviews_tbl <- tibble(document = 1:length(imdb$review), text = imdb$review)

# Tokenizar, remover stopwords e contar frequências
word_freq <- reviews_tbl %>%
  unnest_tokens(word, text) %>%
  filter(!word %in% stop_words$word,
         str_detect(word, "^[a-z']+$")) %>%
  count(word, sort = TRUE)

# Mostrar top 15 palavras
head(word_freq, 15)

# Gráfico das 20 palavras mais frequentes
word_freq %>%
  top_n(20, n) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "20 palavras mais frequentes nas resenhas",
       x = "Palavra", y = "Frequência")

```

# Questões

## Questão 1

### 1a) Algum tópico parece estar relacionado a emoção ou julgamento dos filmes? (ex: *great*, *bad*, *boring*). Quais palavras caracterizam cada um dos 4 tópicos? Dê um título para cada um. Dica: faça uma nuvem de palavras para cada tópico.

```{r}

dfm <- tidy(dtm) %>%
  cast_dfm(document = document, 
           term = term, 
           value = count)

lda4 <- stm(dfm, 
            K = 4, 
            verbose = FALSE, 
            init.type = "LDA",
            seed = 42)

cloud(lda4, 1)
cloud(lda4, 2)
cloud(lda4, 3)
cloud(lda4, 4)

summary(lda4)
plot(lda4)
```

Utilizando as nuvens de palavras + as palavras apresentadas no *summary*; 

- Tópico 1: **enredo**
  Palavras usadas: "funny", "original", "hollywood", "real", "characters"...
- Tópico 2: **comparação**
  Palavras usadas: "better", "even", "work", "look", "quite"...
- Tópico 3: **reações/julgamento**
  Palavras usadas: "bad", "stupid", "love", "think", "really"...
- Tópico 4: **qualidade/característica**
  Palavras usadas: "good", "actually", "actors", "old", "pretty", "director", "time"...
  

### 1b) Indique a probabilidade das palavras para cada um dos tópicos, faça um gráfico com as 10 palavras mais prováveis por tópico.

```{r}

# Converter o modelo stm para formato tidy
tidy_lda <- tidy(lda4)

# Filtrar as top 10 palavras por tópico
top_words <- tidy_lda %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup()

# Gráfico
ggplot(top_words, aes(x = reorder_within(term, beta, topic), y = beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(x = NULL, y = "Probabilidade")
  
```

### 1c) Qual o tópico mais provável para cada documento? Sorteie 3 documentos e avalie essas probabilidades, o tópico mais provável faz sentido dado a divisão da letra a)?

```{r}

set.seed(42)

doc_topics <- tidy(lda4, matrix = "gamma")

plot(lda4)
docs_samp <- sample(1:nrow(lda4$theta), 3)

prob <- lda4$theta[docs_samp, ]
top  <- apply(prob, 1, which.max)

resum <- data.frame(
  doc      = docs_samp,
  prob_top = top,
  ps = apply(prob, 1, function(x) paste(x, collapse = "; "))
)

resum

imdb$review[resum$doc]
```

Considerando as palavras usadas e o fato de que os tópicos são de certa forma "genéricos" podemos dizer que faz sentido essa classificação, apesar de ser difícil a diferenciação entre tópicos. 

### 1d) Faça um gráfico com as frequencias da distribuição dos tópicos mais prováveis por documento.

```{r}

topic_distribution <- doc_topics %>%
  group_by(document) %>%
  slice_max(gamma, n = 1) %>%
  ungroup()

ggplot(topic_distribution, aes(x = factor(topic), fill = factor(topic))) +
  geom_bar(stat = "count") +
  labs(
    x = "Tópico",
    y = "Número de Documentos",
    title = "Distribuição dos Tópicos Mais Prováveis por Documento",
    fill = "Tópico"
  ) +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "Set2")

```

## Questão 2

Altere o número de tópicos para `k = 6`. Refaça as análises da questão 1. Os temas ficaram mais claros ou mais difusos?

### 2a)

```{r}

dfm <- tidy(dtm) %>%
  cast_dfm(document = document, 
           term = term, 
           value = count)

lda6 <- stm(dfm, 
            K = 6, 
            verbose = FALSE, 
            init.type = "LDA",
            seed = 42)

cloud(lda6, 1)
cloud(lda6, 2)
cloud(lda6, 3)
cloud(lda6, 4)

summary(lda6)
plot(lda6)
```


### 2b)

```{r}

# Converter o modelo stm para formato tidy
tidy_lda <- tidy(lda6)

# Filtrar as top 10 palavras por tópico
top_words <- tidy_lda %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup()

# Gráfico
ggplot(top_words, aes(x = reorder_within(term, beta, topic), y = beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(x = NULL, y = "Probabilidade")
  
```

### 2c)

```{r}

set.seed(42)

doc_topics <- tidy(lda6, matrix = "gamma")

plot(lda6)
docs_samp <- sample(1:nrow(lda6$theta), 3)

prob <- lda6$theta[docs_samp, ]
top  <- apply(prob, 1, which.max)

resum <- data.frame(
  doc      = docs_samp,
  prob_top = top,
  ps = apply(prob, 1, function(x) paste(x, collapse = "; "))
)

resum
```

### 2d)

```{r}

topic_distribution <- doc_topics %>%
  group_by(document) %>%
  slice_max(gamma, n = 1) %>%
  ungroup()

ggplot(topic_distribution, aes(x = factor(topic), fill = factor(topic))) +
  geom_bar(stat = "count") +
  labs(
    x = "Tópico",
    y = "Número de Documentos",
    title = "Distribuição dos Tópicos Mais Prováveis por Documento",
    fill = "Tópico"
  ) +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "Set2")

```

### Conclusão sobre os tópicos; 

A separação proporcionou mais clareza em relação a k = 4. 
Como podemos ver no item c a probabilidade não ficou tão equilibrada entre todos os tópicos como anteriormente. Os tópicos também estão menos "genéricos".


## Questão 3

Altere o número de tópicos para `k = 2`. Os temas ficaram mais claros ou mais difusos?

### 3a)

```{r}

dfm <- tidy(dtm) %>%
  cast_dfm(document = document, 
           term = term, 
           value = count)

lda2 <- stm(dfm, 
            K = 2, 
            verbose = FALSE, 
            init.type = "LDA",
            seed = 42)

cloud(lda2, 1)
cloud(lda2, 2)

summary(lda2)
plot(lda2)
```

### 3b)

```{r}
# Converter o modelo stm para formato tidy
tidy_lda <- tidy(lda2)

# Filtrar as top 10 palavras por tópico
top_words <- tidy_lda %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup()

# Gráfico
ggplot(top_words, aes(x = reorder_within(term, beta, topic), y = beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(x = NULL, y = "Probabilidade")
```

### 3c)

```{r}
set.seed(42)

doc_topics <- tidy(lda2, matrix = "gamma")

plot(lda2)
docs_samp <- sample(1:nrow(lda2$theta), 3)

prob <- lda2$theta[docs_samp, ]
top  <- apply(prob, 1, which.max)

resum <- data.frame(
  doc      = docs_samp,
  prob_top = top,
  ps = apply(prob, 1, function(x) paste(x, collapse = "; "))
)

resum
```

### 3d)

```{r}

topic_distribution <- doc_topics %>%
  group_by(document) %>%
  slice_max(gamma, n = 1) %>%
  ungroup()

ggplot(topic_distribution, aes(x = factor(topic), fill = factor(topic))) +
  geom_bar(stat = "count") +
  labs(
    x = "Tópico",
    y = "Número de Documentos",
    title = "Distribuição dos Tópicos Mais Prováveis por Documento",
    fill = "Tópico"
  ) +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "Set2")

```

### Conclusão sobre os tópicos;

Com apenas 2 tópicos podemos ver uma distinção entre eles mas é difícil defini-los. Os tópicos ficam mais genéricos e menos claros/objetivos.

## Questão 4

Calcule a perplexidade para k=2, k=4 e k=6. Compare os resultados, qual modelo é o melhor considerando essa métrica?

```{r}

perp <- data.frame(K = c(), Perplexidade = c())

for (k in c(2, 4, 6)) {
  lda_model <- LDA(dtm, k = k, control = list(seed = 42))
  perplex <- perplexity(lda_model, dtm)
  perp <- rbind(perp, data.frame(K = k, Perplexidade = perplex))
}

perp
```
Por essa métrica temos uma diferença muito pequena entre os modelos, mas o modelo com k = 2 é ligeiramente melhor, já que para perplexidade quanto menor melhor.

## Questão 5

Como esse tipo de análise pode ajudar empresas que coletam grandes volumes de texto (ex: SAC, redes sociais)?

Dependendo do ramo da empresa, essa análise pode contribuir muito com a atividade fim, por exemplo: 
empresas de SAC podem identificar problemas/reclamações + recorrentes, automatizar respostas, captar melhor o feedbacks recebidos... Redes sociais podem determinar temas relevantes, segmentar usuários, melhorar recomendações/publicidades...
